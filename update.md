Original plan: 30M parameters → Recommended: 45M parameters
Justification from BitNet research: The BitNet b1.58 Reloaded paper (Nielsen & Schneider-Kamp, 2025) explicitly shows that models <100M parameters need 2× hidden dimensions to compensate for 1.58-bit quantization loss.
Metric30M Original45M RecommendedChangeHidden dimension384512+33%State dimension (Mamba)6496+50%Total parameters30M45M+50%FP16 size60 MB90 MB+50%Quantized 1.58-bit size11.8 MB17.6 MB+50%Expected MMLU boost23-25%27-30%+5% absolute
Trade-off: +50% model size but still <20MB quantized, plus +5-8% accuracy. This is worth it.